{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd8fb1c6",
   "metadata": {},
   "source": [
    "### Hop-Typed Communication Model (NVLink vs NDR) for **LLaMA-3 8B**\n",
    "\n",
    "This notebook estimates the communication **latency** and **energy** incurred when training or serving LLaMA-3 8B on a DGX-H100.  Each network hop is classified as **NVLink 4** or **InfiniBand NDR 400**, allowing the model to account for the very different bandwidths, startup latencies, and energy costs of those two links.\n",
    "\n",
    "---\n",
    "\n",
    "#### Parallelism Strategies Examined\n",
    "| Strategy | Communication Pattern (per transformer block) |\n",
    "|----------|----------------------------------------------|\n",
    "| **Data Parallel (DP)** | All-reduce of full-precision gradients across all GPUs. |\n",
    "| **Tensor Parallel (TP)** | All-gather the input activations, then reduce-scatter the output activations (equivalent computation as all-reduce) |\n",
    "| **Pipeline Parallel (PP)** | Point-to-point transfer of activation checkpoints between consecutive pipeline stages. *Pipeline bubbles are **not** modeled.* |\n",
    "---\n",
    "\n",
    "We modeled the forward pass for Tensor and Pipeline, and backward pass for Data Parallelism. The backward pass communication is identical for Tensor and Pipeline parallelism, whilst Data Parallelism has no forward pass communication.\n",
    "\n",
    "#### Model Scope\n",
    "- **Architecture:** LLaMA-3 8B  \n",
    "  – 32 transformer layers, hidden size = 4096, multi-query attention  \n",
    "- **Numerics:** FP16 / BF16 (2 B per element)  \n",
    "- **Sequence Length:** 2048 tokens (for activation sizing)\n",
    "\n",
    "Note: We ignore the SwigLU layer for MLP.\n",
    "\n",
    "---\n",
    "\n",
    "#### Hardware Link Constants\n",
    "| Link           | Peak BW                                                          | Startup α                                                | Inverse BW β                                                 | Energy/bit                                                    |\n",
    "|----------------|------------------------------------------------------------------|----------------------------------------------------------|--------------------------------------------------------------|---------------------------------------------------------------|\n",
    "| **NVLink-C2C** | [900 GB/s](https://www.nvidia.com/en-us/data-center/nvlink/)     | ~0 | [1.11 ps/B](https://www.nvidia.com/en-us/data-center/nvlink/) | [1.3 pJ/bit](https://www.nvidia.com/en-us/data-center/nvlink-c2c/) |\n",
    "| **NDR 400**    | [50 GB/s](https://www.nvidia.com/content/dam/en-zz/Solutions/networking/infiniband-adapters/infiniband-connectx7-data-sheet.pdf) | ~0  | [20 ps/B](https://www.nvidia.com/content/dam/en-zz/Solutions/networking/infiniband-adapters/infiniband-connectx7-data-sheet.pdf) | [∼ 20 pJ/bit](calculated from 8W typical power consumption) |\n",
    "\n",
    "\n",
    "A message of size \\(M\\) bytes traversing \\(n_{\\text{NV}}\\) NVLink hops and \\(n_{\\text{IB}}\\) InfiniBand hops incurs  \n",
    "\n",
    "$\n",
    "\\text{Latency} = n_{\\text{NV}}\\bigl(\\alpha_{NV} + \\beta_{NV}M \\bigr) \\;+\\; n_{\\text{IB}}\\bigl(\\alpha_{IB} + \\beta_{IB}M \\bigr),\n",
    "$\n",
    "\n",
    "$\n",
    "\\text{Energy}  = 8M\\bigl(5\\,n_{\\text{NV}} + 25\\,n_{\\text{IB}}\\bigr)\\text{ pJ}.\n",
    "$\n",
    "\n",
    "---\n",
    "\n",
    "#### Objectives of the Notebook\n",
    "1. **Quantify Communication Cost** — Report latency (µs) and energy (nJ) per message for each strategy and hop mix.  \n",
    "2. **Compare Parallel Schemes** — Highlight how DP, TP, and PP trade off communication time and energy under the same hardware assumptions.  \n",
    "3. **Guide Design Decisions** — Provide first-order numbers that help decide which parallelism (or combination) is appropriate for a given training or inference workload.\n",
    "\n",
    "---\n",
    "\n",
    "#### Notebook Outputs\n",
    "- **Per-Hop Latency** and **Energy** tables for each collective or point-to-point operation.  \n",
    "- **Data Volume** moved (MB) per GPU and in aggregate.  \n",
    "- Consolidated **comparative charts** for DP, TP, and PP to illustrate trade-offs.\n",
    "\n",
    "> **Caveat:**  Results are first-order; they do not model overlap, asynchronous progress, or pipeline fill/drain bubbles. They nevertheless capture the dominant communication costs needed for quick design-space exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a9c5b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "\n",
    "# ---------- Hardware Link Constants ----------\n",
    "alpha_nv, beta_nv, epb_nv = 0e-6, 1.11e-12, 1.3e-12\n",
    "alpha_ib, beta_ib, epb_ib = 0e-6, 20e-12, 20e-12\n",
    "\n",
    "# ---------- Model sizes ----------\n",
    "BYTES_FP16 = 2\n",
    "d_model = 4096\n",
    "d_ff    = 14336\n",
    "seq_len = 2048\n",
    "\n",
    "# Self‑attention params (MQA)\n",
    "attn_elems = d_model*d_model + 2*1024*d_model + d_model*d_model\n",
    "attn_bytes = attn_elems * BYTES_FP16\n",
    "\n",
    "# MLP params (no gate)\n",
    "mlp_elems  = d_ff*d_model + d_model*d_ff\n",
    "mlp_bytes  = mlp_elems  * BYTES_FP16\n",
    "\n",
    "# Activation size (one block output) for PP / TP\n",
    "attn_bytes = seq_len * d_model * BYTES_FP16\n",
    "MLP_bytes = attn_bytes * 4\n",
    "layer_bytes = dict(ATTN=attn_bytes, MLP=mlp_bytes)\n",
    "\n",
    "rows=[]\n",
    "num_gpu_list = [4, 6, 8, 10, 12, 16, 24, 32, 48]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "de7419cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hop tuples (nv, ib)\n",
    "def hops_8():\n",
    "    H = np.empty((8,8),dtype=object)\n",
    "    for i in range(8):\n",
    "        for j in range(8):\n",
    "            if i==j: H[i,j]=(0,0)\n",
    "            else:    H[i,j]=(1,0)   # single NV hop for any pair\n",
    "    return H\n",
    "\n",
    "def hops_16():\n",
    "    H = np.empty((16,16),dtype=object)\n",
    "    for i in range(16):\n",
    "        for j in range(16):\n",
    "            if i==j: H[i,j]=(0,0)\n",
    "            else:\n",
    "                same_node=(i//8)==(j//8)\n",
    "                if same_node: H[i,j]=(1,0)\n",
    "                else:         H[i,j]=(2,1)  # GPU→NV + IB + NV\n",
    "    return H\n",
    "\n",
    "def hop_9():\n",
    "    H = np.empty((9,9),dtype=object)\n",
    "    for i in range(9):\n",
    "        for j in range(9):\n",
    "            if i==j: H[i,j]=(0,0)\n",
    "            else: \n",
    "                same_node=(i//8)==(j//8)\n",
    "                if same_node: H[i,j]=(1,0)\n",
    "                else:         H[i,j]=(2,1)  # GPU→NV + IB + NV\n",
    "    return H\n",
    "\n",
    "def hops(num_gpus):\n",
    "    H = np.empty((num_gpus,num_gpus),dtype=object)\n",
    "    for i in range(num_gpus):\n",
    "        for j in range(num_gpus):\n",
    "            if i==j: H[i,j]=(0,0)\n",
    "            else:\n",
    "                same_node=(i//8)==(j//8)\n",
    "                if same_node: H[i,j]=(1,0)\n",
    "                else:         H[i,j]=(2,1)  # GPU→NV + IB + NV\n",
    "    return H\n",
    "\n",
    "# Test the correctness of the function via the handwritten ones\n",
    "hop8 = hops_8()\n",
    "hop9 = hop_9()\n",
    "hop16 = hops_16()\n",
    "assert np.all(hops(8) == hop8)\n",
    "assert np.all(hops(16) == hop16)\n",
    "assert np.all(hops(9) == hop9) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "09dff8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_bytes(lat_bytes, nv_hops, ib_hops):\n",
    "    lat = nv_hops*(alpha_nv+beta_nv*lat_bytes) + ib_hops*(alpha_ib+beta_ib*lat_bytes)\n",
    "    eng = nv_hops*lat_bytes*8*epb_nv + ib_hops*lat_bytes*8*epb_ib\n",
    "    return lat, eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19087651",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ring_dp(layer_name, layer_b, hopmat, mode_label):\n",
    "    n = hopmat.shape[0]\n",
    "    chunk = layer_b / n                      # bytes sent per link per step\n",
    "    per_gpu_bytes = layer_b * (n - 1) / n    # textbook formula\n",
    "    steps = 2 * (n - 1)                      # reduce-scatter + all-gather\n",
    "\n",
    "    total_lat = 0.0\n",
    "    total_eng = 0.0\n",
    "\n",
    "    for _ in range(steps):\n",
    "        max_link_lat = 0.0\n",
    "        step_energy  = 0.0\n",
    "\n",
    "        # each rank communicates with its neighbour every step\n",
    "        for r in range(n):\n",
    "            sender    = r\n",
    "            receiver  = (r + 1) % n          # fixed clockwise ring\n",
    "            nv, ib     = hopmat[sender, receiver]\n",
    "            lat, eng   = cost_bytes(chunk, nv, ib)\n",
    "\n",
    "            max_link_lat = max(max_link_lat, lat)\n",
    "            step_energy += eng               # all links consume energy\n",
    "\n",
    "        total_lat += max_link_lat            # critical-path latency\n",
    "        total_eng += step_energy\n",
    "\n",
    "    rows.append([layer_name, mode_label,\n",
    "                 per_gpu_bytes / 1e6,        # MiB\n",
    "                 total_lat  * 1e3,           # µs\n",
    "                 total_eng  * 1e3])          # nJ\n",
    "\n",
    "for L,B in layer_bytes.items():\n",
    "    for num_gpu in num_gpu_list:\n",
    "        ring_dp(L,B,hops(num_gpu),f\"DP-{num_gpu}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2deb6e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tp_cost(layer_name, bytes_per_msg, hopmat, ring_dp=ring_dp, num_gpus=8):\n",
    "    # reduce‑scatter + all‑reduce = 2 msgs; each msg one NV hop\n",
    "    ring_dp(layer_name, bytes_per_msg, hopmat, \"TP‑\" + str(num_gpus))\n",
    "\n",
    "for num_gpu in num_gpu_list:\n",
    "    tp_cost(\"ATTN\", layer_bytes[\"ATTN\"], hops(num_gpu), num_gpus=num_gpu)\n",
    "    tp_cost(\"MLP\" , layer_bytes[\"MLP\"], hops(num_gpu), num_gpus=num_gpu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "009181ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pp_cost(label, act_bytes, nv_hops, ib_hops):\n",
    "    lat,eng = cost_bytes(act_bytes,nv_hops,ib_hops)\n",
    "    rows.append([\"BLOCK\",label,act_bytes/1e6,lat*1e3,eng*1e3])\n",
    "\n",
    "pp_cost(\"PP‑NV-ATTN\",layer_bytes[\"ATTN\"],0,0)\n",
    "pp_cost(\"PP‑Cross-ATTN\",layer_bytes[\"ATTN\"],2,1)\n",
    "pp_cost(\"PP‑NV-MLP\",layer_bytes[\"MLP\"],0,0)\n",
    "pp_cost(\"PP‑Cross-MLP\",layer_bytes[\"MLP\"],2,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "666ddda7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Layer</th>\n",
       "      <th>Mode</th>\n",
       "      <th>PerGPU_MB</th>\n",
       "      <th>PerGPU_MiB</th>\n",
       "      <th>Latency_ms</th>\n",
       "      <th>Energy_mJ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ATTN</td>\n",
       "      <td>DP-4</td>\n",
       "      <td>12.583</td>\n",
       "      <td>12.000</td>\n",
       "      <td>0.028</td>\n",
       "      <td>1.047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ATTN</td>\n",
       "      <td>DP-6</td>\n",
       "      <td>13.981</td>\n",
       "      <td>13.333</td>\n",
       "      <td>0.031</td>\n",
       "      <td>1.745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ATTN</td>\n",
       "      <td>DP-8</td>\n",
       "      <td>14.680</td>\n",
       "      <td>14.000</td>\n",
       "      <td>0.033</td>\n",
       "      <td>2.443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ATTN</td>\n",
       "      <td>DP-10</td>\n",
       "      <td>15.099</td>\n",
       "      <td>14.400</td>\n",
       "      <td>0.671</td>\n",
       "      <td>13.433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ATTN</td>\n",
       "      <td>DP-12</td>\n",
       "      <td>15.379</td>\n",
       "      <td>14.667</td>\n",
       "      <td>0.683</td>\n",
       "      <td>14.321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ATTN</td>\n",
       "      <td>DP-16</td>\n",
       "      <td>15.729</td>\n",
       "      <td>15.000</td>\n",
       "      <td>0.699</td>\n",
       "      <td>15.955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ATTN</td>\n",
       "      <td>DP-24</td>\n",
       "      <td>16.078</td>\n",
       "      <td>15.333</td>\n",
       "      <td>0.715</td>\n",
       "      <td>24.465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ATTN</td>\n",
       "      <td>DP-32</td>\n",
       "      <td>16.253</td>\n",
       "      <td>15.500</td>\n",
       "      <td>0.722</td>\n",
       "      <td>32.974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ATTN</td>\n",
       "      <td>DP-48</td>\n",
       "      <td>16.428</td>\n",
       "      <td>15.667</td>\n",
       "      <td>0.730</td>\n",
       "      <td>49.993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MLP</td>\n",
       "      <td>DP-4</td>\n",
       "      <td>176.161</td>\n",
       "      <td>168.000</td>\n",
       "      <td>0.391</td>\n",
       "      <td>14.657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MLP</td>\n",
       "      <td>DP-6</td>\n",
       "      <td>195.734</td>\n",
       "      <td>186.667</td>\n",
       "      <td>0.435</td>\n",
       "      <td>24.428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MLP</td>\n",
       "      <td>DP-8</td>\n",
       "      <td>205.521</td>\n",
       "      <td>196.000</td>\n",
       "      <td>0.456</td>\n",
       "      <td>34.199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>MLP</td>\n",
       "      <td>DP-10</td>\n",
       "      <td>211.393</td>\n",
       "      <td>201.600</td>\n",
       "      <td>9.394</td>\n",
       "      <td>188.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>MLP</td>\n",
       "      <td>DP-12</td>\n",
       "      <td>215.308</td>\n",
       "      <td>205.333</td>\n",
       "      <td>9.568</td>\n",
       "      <td>200.494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>MLP</td>\n",
       "      <td>DP-16</td>\n",
       "      <td>220.201</td>\n",
       "      <td>210.000</td>\n",
       "      <td>9.786</td>\n",
       "      <td>223.372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>MLP</td>\n",
       "      <td>DP-24</td>\n",
       "      <td>225.094</td>\n",
       "      <td>214.667</td>\n",
       "      <td>10.003</td>\n",
       "      <td>342.504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>MLP</td>\n",
       "      <td>DP-32</td>\n",
       "      <td>227.541</td>\n",
       "      <td>217.000</td>\n",
       "      <td>10.112</td>\n",
       "      <td>461.635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>MLP</td>\n",
       "      <td>DP-48</td>\n",
       "      <td>229.988</td>\n",
       "      <td>219.333</td>\n",
       "      <td>10.221</td>\n",
       "      <td>699.898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ATTN</td>\n",
       "      <td>TP‑4</td>\n",
       "      <td>12.583</td>\n",
       "      <td>12.000</td>\n",
       "      <td>0.028</td>\n",
       "      <td>1.047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>MLP</td>\n",
       "      <td>TP‑4</td>\n",
       "      <td>176.161</td>\n",
       "      <td>168.000</td>\n",
       "      <td>0.391</td>\n",
       "      <td>14.657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ATTN</td>\n",
       "      <td>TP‑6</td>\n",
       "      <td>13.981</td>\n",
       "      <td>13.333</td>\n",
       "      <td>0.031</td>\n",
       "      <td>1.745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>MLP</td>\n",
       "      <td>TP‑6</td>\n",
       "      <td>195.734</td>\n",
       "      <td>186.667</td>\n",
       "      <td>0.435</td>\n",
       "      <td>24.428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ATTN</td>\n",
       "      <td>TP‑8</td>\n",
       "      <td>14.680</td>\n",
       "      <td>14.000</td>\n",
       "      <td>0.033</td>\n",
       "      <td>2.443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>MLP</td>\n",
       "      <td>TP‑8</td>\n",
       "      <td>205.521</td>\n",
       "      <td>196.000</td>\n",
       "      <td>0.456</td>\n",
       "      <td>34.199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ATTN</td>\n",
       "      <td>TP‑10</td>\n",
       "      <td>15.099</td>\n",
       "      <td>14.400</td>\n",
       "      <td>0.671</td>\n",
       "      <td>13.433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>MLP</td>\n",
       "      <td>TP‑10</td>\n",
       "      <td>211.393</td>\n",
       "      <td>201.600</td>\n",
       "      <td>9.394</td>\n",
       "      <td>188.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ATTN</td>\n",
       "      <td>TP‑12</td>\n",
       "      <td>15.379</td>\n",
       "      <td>14.667</td>\n",
       "      <td>0.683</td>\n",
       "      <td>14.321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>MLP</td>\n",
       "      <td>TP‑12</td>\n",
       "      <td>215.308</td>\n",
       "      <td>205.333</td>\n",
       "      <td>9.568</td>\n",
       "      <td>200.494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ATTN</td>\n",
       "      <td>TP‑16</td>\n",
       "      <td>15.729</td>\n",
       "      <td>15.000</td>\n",
       "      <td>0.699</td>\n",
       "      <td>15.955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>MLP</td>\n",
       "      <td>TP‑16</td>\n",
       "      <td>220.201</td>\n",
       "      <td>210.000</td>\n",
       "      <td>9.786</td>\n",
       "      <td>223.372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ATTN</td>\n",
       "      <td>TP‑24</td>\n",
       "      <td>16.078</td>\n",
       "      <td>15.333</td>\n",
       "      <td>0.715</td>\n",
       "      <td>24.465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>MLP</td>\n",
       "      <td>TP‑24</td>\n",
       "      <td>225.094</td>\n",
       "      <td>214.667</td>\n",
       "      <td>10.003</td>\n",
       "      <td>342.504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ATTN</td>\n",
       "      <td>TP‑32</td>\n",
       "      <td>16.253</td>\n",
       "      <td>15.500</td>\n",
       "      <td>0.722</td>\n",
       "      <td>32.974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>MLP</td>\n",
       "      <td>TP‑32</td>\n",
       "      <td>227.541</td>\n",
       "      <td>217.000</td>\n",
       "      <td>10.112</td>\n",
       "      <td>461.635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>ATTN</td>\n",
       "      <td>TP‑48</td>\n",
       "      <td>16.428</td>\n",
       "      <td>15.667</td>\n",
       "      <td>0.730</td>\n",
       "      <td>49.993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>MLP</td>\n",
       "      <td>TP‑48</td>\n",
       "      <td>229.988</td>\n",
       "      <td>219.333</td>\n",
       "      <td>10.221</td>\n",
       "      <td>699.898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>BLOCK</td>\n",
       "      <td>PP‑NV-ATTN</td>\n",
       "      <td>16.777</td>\n",
       "      <td>16.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>BLOCK</td>\n",
       "      <td>PP‑Cross-ATTN</td>\n",
       "      <td>16.777</td>\n",
       "      <td>16.000</td>\n",
       "      <td>0.373</td>\n",
       "      <td>3.033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>BLOCK</td>\n",
       "      <td>PP‑NV-MLP</td>\n",
       "      <td>234.881</td>\n",
       "      <td>224.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>BLOCK</td>\n",
       "      <td>PP‑Cross-MLP</td>\n",
       "      <td>234.881</td>\n",
       "      <td>224.000</td>\n",
       "      <td>5.219</td>\n",
       "      <td>42.466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Layer           Mode  PerGPU_MB  PerGPU_MiB  Latency_ms  Energy_mJ\n",
       "0    ATTN           DP-4     12.583      12.000       0.028      1.047\n",
       "1    ATTN           DP-6     13.981      13.333       0.031      1.745\n",
       "2    ATTN           DP-8     14.680      14.000       0.033      2.443\n",
       "3    ATTN          DP-10     15.099      14.400       0.671     13.433\n",
       "4    ATTN          DP-12     15.379      14.667       0.683     14.321\n",
       "5    ATTN          DP-16     15.729      15.000       0.699     15.955\n",
       "6    ATTN          DP-24     16.078      15.333       0.715     24.465\n",
       "7    ATTN          DP-32     16.253      15.500       0.722     32.974\n",
       "8    ATTN          DP-48     16.428      15.667       0.730     49.993\n",
       "9     MLP           DP-4    176.161     168.000       0.391     14.657\n",
       "10    MLP           DP-6    195.734     186.667       0.435     24.428\n",
       "11    MLP           DP-8    205.521     196.000       0.456     34.199\n",
       "12    MLP          DP-10    211.393     201.600       9.394    188.055\n",
       "13    MLP          DP-12    215.308     205.333       9.568    200.494\n",
       "14    MLP          DP-16    220.201     210.000       9.786    223.372\n",
       "15    MLP          DP-24    225.094     214.667      10.003    342.504\n",
       "16    MLP          DP-32    227.541     217.000      10.112    461.635\n",
       "17    MLP          DP-48    229.988     219.333      10.221    699.898\n",
       "18   ATTN           TP‑4     12.583      12.000       0.028      1.047\n",
       "19    MLP           TP‑4    176.161     168.000       0.391     14.657\n",
       "20   ATTN           TP‑6     13.981      13.333       0.031      1.745\n",
       "21    MLP           TP‑6    195.734     186.667       0.435     24.428\n",
       "22   ATTN           TP‑8     14.680      14.000       0.033      2.443\n",
       "23    MLP           TP‑8    205.521     196.000       0.456     34.199\n",
       "24   ATTN          TP‑10     15.099      14.400       0.671     13.433\n",
       "25    MLP          TP‑10    211.393     201.600       9.394    188.055\n",
       "26   ATTN          TP‑12     15.379      14.667       0.683     14.321\n",
       "27    MLP          TP‑12    215.308     205.333       9.568    200.494\n",
       "28   ATTN          TP‑16     15.729      15.000       0.699     15.955\n",
       "29    MLP          TP‑16    220.201     210.000       9.786    223.372\n",
       "30   ATTN          TP‑24     16.078      15.333       0.715     24.465\n",
       "31    MLP          TP‑24    225.094     214.667      10.003    342.504\n",
       "32   ATTN          TP‑32     16.253      15.500       0.722     32.974\n",
       "33    MLP          TP‑32    227.541     217.000      10.112    461.635\n",
       "34   ATTN          TP‑48     16.428      15.667       0.730     49.993\n",
       "35    MLP          TP‑48    229.988     219.333      10.221    699.898\n",
       "36  BLOCK     PP‑NV-ATTN     16.777      16.000       0.000      0.000\n",
       "37  BLOCK  PP‑Cross-ATTN     16.777      16.000       0.373      3.033\n",
       "38  BLOCK      PP‑NV-MLP    234.881     224.000       0.000      0.000\n",
       "39  BLOCK   PP‑Cross-MLP    234.881     224.000       5.219     42.466"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df=pd.DataFrame(rows,columns=[\"Layer\",\"Mode\",\"PerGPU_MB\",\"Latency_ms\",\"Energy_mJ\"])\n",
    "df.round(3)\n",
    "\n",
    "# Derive group size from the Mode label\n",
    "def _group_size(mode: str) -> int:\n",
    "    if \"-8\"  in mode: return 8\n",
    "    if \"-16\" in mode: return 16\n",
    "    # For pipeline-parallel point-to-point assume two ranks\n",
    "    return 2\n",
    "\n",
    "df[\"Group\"] = df[\"Mode\"].map(_group_size)\n",
    "\n",
    "df[\"Total_MB\"] = df[\"PerGPU_MB\"] * df[\"Group\"]\n",
    "\n",
    "# Show binary MiB alongside decimal MB\n",
    "MB2MiB = 1_000_000 / 1_048_576         # ≈ 0.953674\n",
    "df[\"PerGPU_MiB\"] = df[\"PerGPU_MB\"] * MB2MiB\n",
    "\n",
    "# Re-order columns for readability\n",
    "cols = [\"Layer\",\"Mode\",\n",
    "        \"PerGPU_MB\",\n",
    "        \"PerGPU_MiB\",\n",
    "        \"Latency_ms\",\"Energy_mJ\"]\n",
    "df = df[cols]\n",
    "\n",
    "display(df.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761b0be7",
   "metadata": {},
   "source": [
    "# Adding forward/backward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ce9b0c11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Layer</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Workload</th>\n",
       "      <th>PerGPU_MB</th>\n",
       "      <th>PerGPU_MiB</th>\n",
       "      <th>Latency_ms</th>\n",
       "      <th>Energy_mJ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ATTN</td>\n",
       "      <td>DP-48</td>\n",
       "      <td>backward pass</td>\n",
       "      <td>16.42769</td>\n",
       "      <td>15.66667</td>\n",
       "      <td>0.73005</td>\n",
       "      <td>49.99275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ATTN</td>\n",
       "      <td>DP-32</td>\n",
       "      <td>backward pass</td>\n",
       "      <td>16.25293</td>\n",
       "      <td>15.50000</td>\n",
       "      <td>0.72228</td>\n",
       "      <td>32.97394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ATTN</td>\n",
       "      <td>DP-24</td>\n",
       "      <td>backward pass</td>\n",
       "      <td>16.07817</td>\n",
       "      <td>15.33333</td>\n",
       "      <td>0.71451</td>\n",
       "      <td>24.46454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ATTN</td>\n",
       "      <td>DP-16</td>\n",
       "      <td>backward pass</td>\n",
       "      <td>15.72864</td>\n",
       "      <td>15.00000</td>\n",
       "      <td>0.69898</td>\n",
       "      <td>15.95513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ATTN</td>\n",
       "      <td>DP-12</td>\n",
       "      <td>backward pass</td>\n",
       "      <td>15.37911</td>\n",
       "      <td>14.66667</td>\n",
       "      <td>0.68345</td>\n",
       "      <td>14.32103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ATTN</td>\n",
       "      <td>DP-10</td>\n",
       "      <td>backward pass</td>\n",
       "      <td>15.09949</td>\n",
       "      <td>14.40000</td>\n",
       "      <td>0.67102</td>\n",
       "      <td>13.43251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ATTN</td>\n",
       "      <td>DP-8</td>\n",
       "      <td>backward pass</td>\n",
       "      <td>14.68006</td>\n",
       "      <td>14.00000</td>\n",
       "      <td>0.03259</td>\n",
       "      <td>2.44276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ATTN</td>\n",
       "      <td>DP-6</td>\n",
       "      <td>backward pass</td>\n",
       "      <td>13.98101</td>\n",
       "      <td>13.33333</td>\n",
       "      <td>0.03104</td>\n",
       "      <td>1.74483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ATTN</td>\n",
       "      <td>DP-4</td>\n",
       "      <td>backward pass</td>\n",
       "      <td>12.58291</td>\n",
       "      <td>12.00000</td>\n",
       "      <td>0.02793</td>\n",
       "      <td>1.04690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ATTN</td>\n",
       "      <td>TP‑4</td>\n",
       "      <td>backward pass</td>\n",
       "      <td>12.58291</td>\n",
       "      <td>12.00000</td>\n",
       "      <td>0.02793</td>\n",
       "      <td>1.04690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ATTN</td>\n",
       "      <td>TP‑6</td>\n",
       "      <td>backward pass</td>\n",
       "      <td>13.98101</td>\n",
       "      <td>13.33333</td>\n",
       "      <td>0.03104</td>\n",
       "      <td>1.74483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ATTN</td>\n",
       "      <td>TP‑8</td>\n",
       "      <td>backward pass</td>\n",
       "      <td>14.68006</td>\n",
       "      <td>14.00000</td>\n",
       "      <td>0.03259</td>\n",
       "      <td>2.44276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ATTN</td>\n",
       "      <td>TP‑10</td>\n",
       "      <td>backward pass</td>\n",
       "      <td>15.09949</td>\n",
       "      <td>14.40000</td>\n",
       "      <td>0.67102</td>\n",
       "      <td>13.43251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ATTN</td>\n",
       "      <td>TP‑12</td>\n",
       "      <td>backward pass</td>\n",
       "      <td>15.37911</td>\n",
       "      <td>14.66667</td>\n",
       "      <td>0.68345</td>\n",
       "      <td>14.32103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ATTN</td>\n",
       "      <td>TP‑16</td>\n",
       "      <td>backward pass</td>\n",
       "      <td>15.72864</td>\n",
       "      <td>15.00000</td>\n",
       "      <td>0.69898</td>\n",
       "      <td>15.95513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ATTN</td>\n",
       "      <td>TP‑24</td>\n",
       "      <td>backward pass</td>\n",
       "      <td>16.07817</td>\n",
       "      <td>15.33333</td>\n",
       "      <td>0.71451</td>\n",
       "      <td>24.46454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ATTN</td>\n",
       "      <td>TP‑32</td>\n",
       "      <td>backward pass</td>\n",
       "      <td>16.25293</td>\n",
       "      <td>15.50000</td>\n",
       "      <td>0.72228</td>\n",
       "      <td>32.97394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ATTN</td>\n",
       "      <td>TP‑48</td>\n",
       "      <td>backward pass</td>\n",
       "      <td>16.42769</td>\n",
       "      <td>15.66667</td>\n",
       "      <td>0.73005</td>\n",
       "      <td>49.99275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>BLOCK</td>\n",
       "      <td>PP‑NV-ATTN</td>\n",
       "      <td>backward pass</td>\n",
       "      <td>16.77722</td>\n",
       "      <td>16.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>BLOCK</td>\n",
       "      <td>PP‑Cross-ATTN</td>\n",
       "      <td>backward pass</td>\n",
       "      <td>16.77722</td>\n",
       "      <td>16.00000</td>\n",
       "      <td>0.37279</td>\n",
       "      <td>3.03332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>BLOCK</td>\n",
       "      <td>PP‑NV-MLP</td>\n",
       "      <td>backward pass</td>\n",
       "      <td>234.88102</td>\n",
       "      <td>224.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>BLOCK</td>\n",
       "      <td>PP‑Cross-MLP</td>\n",
       "      <td>backward pass</td>\n",
       "      <td>234.88102</td>\n",
       "      <td>224.00000</td>\n",
       "      <td>5.21906</td>\n",
       "      <td>42.46649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>MLP</td>\n",
       "      <td>DP-48</td>\n",
       "      <td>backward pass</td>\n",
       "      <td>229.98767</td>\n",
       "      <td>219.33333</td>\n",
       "      <td>10.22065</td>\n",
       "      <td>699.89848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>MLP</td>\n",
       "      <td>DP-32</td>\n",
       "      <td>backward pass</td>\n",
       "      <td>227.54099</td>\n",
       "      <td>217.00000</td>\n",
       "      <td>10.11192</td>\n",
       "      <td>461.63516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>MLP</td>\n",
       "      <td>DP-24</td>\n",
       "      <td>backward pass</td>\n",
       "      <td>225.09431</td>\n",
       "      <td>214.66667</td>\n",
       "      <td>10.00319</td>\n",
       "      <td>342.50351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>MLP</td>\n",
       "      <td>DP-16</td>\n",
       "      <td>backward pass</td>\n",
       "      <td>220.20096</td>\n",
       "      <td>210.00000</td>\n",
       "      <td>9.78573</td>\n",
       "      <td>223.37185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>MLP</td>\n",
       "      <td>DP-12</td>\n",
       "      <td>backward pass</td>\n",
       "      <td>215.30761</td>\n",
       "      <td>205.33333</td>\n",
       "      <td>9.56827</td>\n",
       "      <td>200.49444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>MLP</td>\n",
       "      <td>DP-10</td>\n",
       "      <td>backward pass</td>\n",
       "      <td>211.39292</td>\n",
       "      <td>201.60000</td>\n",
       "      <td>9.39430</td>\n",
       "      <td>188.05514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>MLP</td>\n",
       "      <td>DP-8</td>\n",
       "      <td>backward pass</td>\n",
       "      <td>205.52090</td>\n",
       "      <td>196.00000</td>\n",
       "      <td>0.45626</td>\n",
       "      <td>34.19868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>MLP</td>\n",
       "      <td>DP-6</td>\n",
       "      <td>backward pass</td>\n",
       "      <td>195.73419</td>\n",
       "      <td>186.66667</td>\n",
       "      <td>0.43453</td>\n",
       "      <td>24.42763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>MLP</td>\n",
       "      <td>DP-4</td>\n",
       "      <td>backward pass</td>\n",
       "      <td>176.16077</td>\n",
       "      <td>168.00000</td>\n",
       "      <td>0.39108</td>\n",
       "      <td>14.65658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>MLP</td>\n",
       "      <td>TP‑4</td>\n",
       "      <td>backward pass</td>\n",
       "      <td>176.16077</td>\n",
       "      <td>168.00000</td>\n",
       "      <td>0.39108</td>\n",
       "      <td>14.65658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>MLP</td>\n",
       "      <td>TP‑6</td>\n",
       "      <td>backward pass</td>\n",
       "      <td>195.73419</td>\n",
       "      <td>186.66667</td>\n",
       "      <td>0.43453</td>\n",
       "      <td>24.42763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>MLP</td>\n",
       "      <td>TP‑8</td>\n",
       "      <td>backward pass</td>\n",
       "      <td>205.52090</td>\n",
       "      <td>196.00000</td>\n",
       "      <td>0.45626</td>\n",
       "      <td>34.19868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>MLP</td>\n",
       "      <td>TP‑10</td>\n",
       "      <td>backward pass</td>\n",
       "      <td>211.39292</td>\n",
       "      <td>201.60000</td>\n",
       "      <td>9.39430</td>\n",
       "      <td>188.05514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>MLP</td>\n",
       "      <td>TP‑12</td>\n",
       "      <td>backward pass</td>\n",
       "      <td>215.30761</td>\n",
       "      <td>205.33333</td>\n",
       "      <td>9.56827</td>\n",
       "      <td>200.49444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>MLP</td>\n",
       "      <td>TP‑16</td>\n",
       "      <td>backward pass</td>\n",
       "      <td>220.20096</td>\n",
       "      <td>210.00000</td>\n",
       "      <td>9.78573</td>\n",
       "      <td>223.37185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>MLP</td>\n",
       "      <td>TP‑24</td>\n",
       "      <td>backward pass</td>\n",
       "      <td>225.09431</td>\n",
       "      <td>214.66667</td>\n",
       "      <td>10.00319</td>\n",
       "      <td>342.50351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>MLP</td>\n",
       "      <td>TP‑32</td>\n",
       "      <td>backward pass</td>\n",
       "      <td>227.54099</td>\n",
       "      <td>217.00000</td>\n",
       "      <td>10.11192</td>\n",
       "      <td>461.63516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>MLP</td>\n",
       "      <td>TP‑48</td>\n",
       "      <td>backward pass</td>\n",
       "      <td>229.98767</td>\n",
       "      <td>219.33333</td>\n",
       "      <td>10.22065</td>\n",
       "      <td>699.89848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Layer           Mode       Workload  PerGPU_MB  PerGPU_MiB  Latency_ms  \\\n",
       "0    ATTN          DP-48  backward pass   16.42769    15.66667     0.73005   \n",
       "2    ATTN          DP-32  backward pass   16.25293    15.50000     0.72228   \n",
       "4    ATTN          DP-24  backward pass   16.07817    15.33333     0.71451   \n",
       "6    ATTN          DP-16  backward pass   15.72864    15.00000     0.69898   \n",
       "8    ATTN          DP-12  backward pass   15.37911    14.66667     0.68345   \n",
       "10   ATTN          DP-10  backward pass   15.09949    14.40000     0.67102   \n",
       "12   ATTN           DP-8  backward pass   14.68006    14.00000     0.03259   \n",
       "14   ATTN           DP-6  backward pass   13.98101    13.33333     0.03104   \n",
       "16   ATTN           DP-4  backward pass   12.58291    12.00000     0.02793   \n",
       "18   ATTN           TP‑4  backward pass   12.58291    12.00000     0.02793   \n",
       "19   ATTN           TP‑6  backward pass   13.98101    13.33333     0.03104   \n",
       "20   ATTN           TP‑8  backward pass   14.68006    14.00000     0.03259   \n",
       "21   ATTN          TP‑10  backward pass   15.09949    14.40000     0.67102   \n",
       "22   ATTN          TP‑12  backward pass   15.37911    14.66667     0.68345   \n",
       "23   ATTN          TP‑16  backward pass   15.72864    15.00000     0.69898   \n",
       "24   ATTN          TP‑24  backward pass   16.07817    15.33333     0.71451   \n",
       "25   ATTN          TP‑32  backward pass   16.25293    15.50000     0.72228   \n",
       "26   ATTN          TP‑48  backward pass   16.42769    15.66667     0.73005   \n",
       "36  BLOCK     PP‑NV-ATTN  backward pass   16.77722    16.00000     0.00000   \n",
       "37  BLOCK  PP‑Cross-ATTN  backward pass   16.77722    16.00000     0.37279   \n",
       "38  BLOCK      PP‑NV-MLP  backward pass  234.88102   224.00000     0.00000   \n",
       "39  BLOCK   PP‑Cross-MLP  backward pass  234.88102   224.00000     5.21906   \n",
       "44    MLP          DP-48  backward pass  229.98767   219.33333    10.22065   \n",
       "46    MLP          DP-32  backward pass  227.54099   217.00000    10.11192   \n",
       "48    MLP          DP-24  backward pass  225.09431   214.66667    10.00319   \n",
       "50    MLP          DP-16  backward pass  220.20096   210.00000     9.78573   \n",
       "52    MLP          DP-12  backward pass  215.30761   205.33333     9.56827   \n",
       "54    MLP          DP-10  backward pass  211.39292   201.60000     9.39430   \n",
       "56    MLP           DP-8  backward pass  205.52090   196.00000     0.45626   \n",
       "58    MLP           DP-6  backward pass  195.73419   186.66667     0.43453   \n",
       "60    MLP           DP-4  backward pass  176.16077   168.00000     0.39108   \n",
       "62    MLP           TP‑4  backward pass  176.16077   168.00000     0.39108   \n",
       "63    MLP           TP‑6  backward pass  195.73419   186.66667     0.43453   \n",
       "64    MLP           TP‑8  backward pass  205.52090   196.00000     0.45626   \n",
       "65    MLP          TP‑10  backward pass  211.39292   201.60000     9.39430   \n",
       "66    MLP          TP‑12  backward pass  215.30761   205.33333     9.56827   \n",
       "67    MLP          TP‑16  backward pass  220.20096   210.00000     9.78573   \n",
       "68    MLP          TP‑24  backward pass  225.09431   214.66667    10.00319   \n",
       "69    MLP          TP‑32  backward pass  227.54099   217.00000    10.11192   \n",
       "70    MLP          TP‑48  backward pass  229.98767   219.33333    10.22065   \n",
       "\n",
       "    Energy_mJ  \n",
       "0    49.99275  \n",
       "2    32.97394  \n",
       "4    24.46454  \n",
       "6    15.95513  \n",
       "8    14.32103  \n",
       "10   13.43251  \n",
       "12    2.44276  \n",
       "14    1.74483  \n",
       "16    1.04690  \n",
       "18    1.04690  \n",
       "19    1.74483  \n",
       "20    2.44276  \n",
       "21   13.43251  \n",
       "22   14.32103  \n",
       "23   15.95513  \n",
       "24   24.46454  \n",
       "25   32.97394  \n",
       "26   49.99275  \n",
       "36    0.00000  \n",
       "37    3.03332  \n",
       "38    0.00000  \n",
       "39   42.46649  \n",
       "44  699.89848  \n",
       "46  461.63516  \n",
       "48  342.50351  \n",
       "50  223.37185  \n",
       "52  200.49444  \n",
       "54  188.05514  \n",
       "56   34.19868  \n",
       "58   24.42763  \n",
       "60   14.65658  \n",
       "62   14.65658  \n",
       "63   24.42763  \n",
       "64   34.19868  \n",
       "65  188.05514  \n",
       "66  200.49444  \n",
       "67  223.37185  \n",
       "68  342.50351  \n",
       "69  461.63516  \n",
       "70  699.89848  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_forward = df.copy()\n",
    "df_backward = df.copy()\n",
    "df_forward['Workload'] = 'forward pass'\n",
    "df_backward['Workload'] = 'backward pass'\n",
    "value_cols = [\"PerGPU_MB\", \"PerGPU_MiB\", \"Latency_ms\", \"Energy_mJ\"]\n",
    "\n",
    "# DP forward pass has 0 communication\n",
    "attn_dp_forward_mask = (df_forward['Workload'].str.contains('forward pass')) & \\\n",
    "                       (df_forward['Mode'].str.contains('DP'))\n",
    "df_forward.loc[attn_dp_forward_mask, value_cols] = 0\n",
    "\n",
    "# Otherwise for TP and PP, the backward pass has the same communication as the forward pass\n",
    "df_processed = pd.concat([df_forward, df_backward], ignore_index=True)\n",
    "\n",
    "cols = [\"Layer\", \"Mode\", \"Workload\",\n",
    "        \"PerGPU_MB\", \"PerGPU_MiB\",\n",
    "        \"Latency_ms\", \"Energy_mJ\"]\n",
    "df_processed = df_processed[cols]\n",
    "\n",
    "# Sort by mode name first, then by num_gpus in descending order\n",
    "def mode_sort_key(mode):\n",
    "    # Extract the prefix (DP, TP, PP) and the number of GPUs\n",
    "    parts = mode.split('-')\n",
    "    prefix = parts[0]\n",
    "    \n",
    "    # For PP modes that don't follow the standard pattern\n",
    "    if prefix.startswith('PP'):\n",
    "        return (2, 0)  # Place PP modes after DP and TP\n",
    "    \n",
    "    # For standard modes with numbers\n",
    "    try:\n",
    "        if len(parts) > 1:\n",
    "            num_gpus = int(parts[1])\n",
    "        else:\n",
    "            num_gpus = 0\n",
    "    except ValueError:\n",
    "        num_gpus = 0\n",
    "    \n",
    "    # Order by prefix (DP=0, TP=1, PP=2), then by -num_gpus for descending order\n",
    "    prefix_order = {'DP': 0, 'TP': 1, 'PP': 2}.get(prefix, 3)\n",
    "    return (prefix_order, -num_gpus)\n",
    "\n",
    "df_processed['mode_sort_key'] = df_processed['Mode'].apply(mode_sort_key)\n",
    "df_processed = df_processed.sort_values(by=[ \"Layer\", \"mode_sort_key\", \"Workload\"]).reset_index(drop=True)\n",
    "df_processed = df_processed.drop(columns=['mode_sort_key'])\n",
    "\n",
    "# Display the final rounded DataFrame\n",
    "display(df_processed.round(5)[df_processed['Workload'] == \"backward pass\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cfc536",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RR-measure",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
